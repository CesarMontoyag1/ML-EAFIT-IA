import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

# =============================
# Generar dataset simulado
# =============================
@st.cache_data
def generar_datos(n_samples=400, n_features=6):
    from sklearn.datasets import make_classification
    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=4,
        n_redundant=0,
        n_classes=3,
        random_state=42
    )
    columnas = [f"feature_{i}" for i in range(X.shape[1])]
    df = pd.DataFrame(X, columns=columnas)
    df["target"] = y
    return df

# =============================
# App Streamlit
# =============================
st.title("üåΩ Clasificaci√≥n de Cultivos con √Årbol de Decisi√≥n")

uploaded_file = st.file_uploader("üìÇ Sube un archivo CSV (ej: con columna 'cultivo')", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("‚úÖ Dataset cargado exitosamente")
else:
    df = generar_datos()
    st.info("‚ÑπÔ∏è Usando dataset simulado")

st.subheader("üìä Vista previa del dataset")
st.write(df.head())

# =============================
# Selecci√≥n de la variable objetivo
# =============================
columnas = df.columns.tolist()
target_col = st.selectbox("Selecciona la columna objetivo (ej: 'cultivo')", columnas, index=len(columnas)-1)

if target_col not in df.columns:
    st.error("‚ùå No se encontr√≥ la columna objetivo seleccionada.")
else:
    X = df.drop(target_col, axis=1)
    y = df[target_col]

    # üîß Convertir variables categ√≥ricas a num√©ricas
    X = pd.get_dummies(X)

    # =============================
    # Divisi√≥n de datos
    # =============================
    test_size = st.slider("Proporci√≥n de prueba", 0.1, 0.5, 0.3, step=0.05)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )

    st.write(f"üëâ Tama√±o entrenamiento: {X_train.shape[0]} | Tama√±o prueba: {X_test.shape[0]}")

    # =============================
    # Par√°metros del √°rbol
    # =============================
    criterion = st.selectbox("Criterio de divisi√≥n", ["gini", "entropy", "log_loss"])
    max_depth = st.slider("Profundidad m√°xima", 1, 20, 5)
    min_samples_split = st.slider("M√≠nimo muestras para dividir", 2, 10, 2)
    min_samples_leaf = st.slider("M√≠nimo muestras por hoja", 1, 10, 1)

    # =============================
    # Entrenar modelo
    # =============================
    clf = DecisionTreeClassifier(
        criterion=criterion,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        random_state=42
    )

    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    # =============================
    # Resultados
    # =============================
    acc = accuracy_score(y_test, y_pred)
    st.subheader("üìà Resultados del Modelo")
    st.write(f"**Exactitud (Accuracy):** {acc:.3f}")

    # Matriz de confusi√≥n
    st.subheader("üìå Matriz de Confusi√≥n")
    cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))
    fig, ax = plt.subplots()
    ConfusionMatrixDisplay(cm, display_labels=np.unique(y)).plot(ax=ax, cmap="Blues", colorbar=False)
    st.pyplot(fig)

    # =============================
    # Visualizaci√≥n del √Årbol
    # =============================
    st.subheader("üå≥ Visualizaci√≥n del √Årbol de Decisi√≥n")
    fig, ax = plt.subplots(figsize=(12, 6))
    plot_tree(clf, filled=True, feature_names=X.columns, class_names=[str(c) for c in np.unique(y)])
    st.pyplot(fig)
