import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report

# =============================
# Configuraci√≥n general
# =============================
st.set_page_config(page_title="√Årbol de Decisi√≥n - Clasificaci√≥n de Cultivos", layout="wide")

# =============================
# Generar dataset simulado (si no se sube CSV)
# =============================
@st.cache_data
def generar_datos(n_samples=400, n_features=6, random_state=42):
    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=4,
        n_redundant=0,
        n_classes=3,
        random_state=random_state
    )
    columnas = [f"feature_{i}" for i in range(X.shape[1])]
    df = pd.DataFrame(X, columns=columnas)
    df["target"] = y
    return df

# =============================
# Sidebar: par√°metros
# =============================
st.sidebar.header("‚öôÔ∏è Par√°metros del modelo")

# Par√°metros del dataset simulado
n_samples = st.sidebar.slider("N√∫mero de muestras (simulado)", 200, 1000, 400, step=50)
n_features = st.sidebar.slider("N√∫mero de caracter√≠sticas (simulado)", 6, 12, 6)
test_size = st.sidebar.slider("Proporci√≥n de prueba", 0.1, 0.5, 0.3, step=0.05)

# Par√°metros del √°rbol de decisi√≥n
criterion = st.sidebar.selectbox("Criterio de divisi√≥n", ["gini", "entropy", "log_loss"])
max_depth = st.sidebar.slider("Profundidad m√°xima", 1, 15, 3)
min_samples_split = st.sidebar.slider("M√≠nimo de muestras para dividir", 2, 20, 2)
min_samples_leaf = st.sidebar.slider("M√≠nimo de muestras en hoja", 1, 20, 1)

# =============================
# Cargar dataset o generar
# =============================
st.title("üåΩüåæü•î Clasificaci√≥n de Cultivos con √Årbol de Decisi√≥n")

uploaded_file = st.file_uploader("Sube un archivo CSV (ej: con columna 'cultivo')", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("‚úÖ Dataset cargado exitosamente")
else:
    df = generar_datos(n_samples=n_samples, n_features=n_features)
    st.info("‚ÑπÔ∏è Usando dataset simulado")

st.subheader("üìä Vista previa del dataset")
st.write(df.head())

# =============================
# Selecci√≥n de la variable objetivo
# =============================
columnas = df.columns.tolist()
target_col = st.selectbox("Selecciona la columna objetivo (ej: 'cultivo')", columnas, index=len(columnas)-1)

if target_col not in df.columns:
    st.error("‚ùå No se encontr√≥ la columna objetivo seleccionada.")
else:
    X = df.drop(target_col, axis=1)
    y = df[target_col]

    # =============================
    # Divisi√≥n de datos
    # =============================
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )

    st.write(f"üëâ Tama√±o entrenamiento: {X_train.shape[0]} | Tama√±o prueba: {X_test.shape[0]}")

    # =============================
    # Entrenar modelo
    # =============================
    clf = DecisionTreeClassifier(
        criterion=criterion,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        random_state=42
    )

    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    # =============================
    # Resultados
    # =============================
    acc = accuracy_score(y_test, y_pred)
    st.subheader("üìà Resultados del Modelo")
    st.write(f"**Exactitud (Accuracy):** {acc:.3f}")

    st.text("üìå Reporte de Clasificaci√≥n:")
    st.text(classification_report(y_test, y_pred))

    # =============================
    # Matriz de confusi√≥n
    # =============================
    st.subheader("üìå Matriz de Confusi√≥n")
    cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))
    fig, ax = plt.subplots()
    ConfusionMatrixDisplay(cm, display_labels=np.unique(y)).plot(ax=ax, cmap="Blues", colorbar=False)
    st.pyplot(fig)

    # =============================
    # Visualizaci√≥n de dispersi√≥n (siempre que haya al menos 2 features num√©ricas)
    # =============================
    if X.shape[1] >= 2:
        st.subheader("üåê Visualizaci√≥n de Clases (2 primeras caracter√≠sticas)")
        fig, ax = plt.subplots()
        scatter = ax.scatter(
            X_test.iloc[:, 0], X_test.iloc[:, 1],
            c=pd.Categorical(y_pred).codes, cmap="viridis", alpha=0.7, edgecolors="k"
        )
        legend1 = ax.legend(*scatter.legend_elements(), title="Clases")
        ax.add_artist(legend1)
        plt.xlabel(X.columns[0])
        plt.ylabel(X.columns[1])
        st.pyplot(fig)

    # =============================
    # Visualizaci√≥n del √Årbol
    # =============================
    st.subheader("üå≥ Visualizaci√≥n del √Årbol de Decisi√≥n")
    fig, ax = plt.subplots(figsize=(14, 6))
    plot_tree(
        clf,
        filled=True,
        feature_names=X.columns,
        class_names=[str(c) for c in np.unique(y)],
        rounded=True
    )
    st.pyplot(fig)
