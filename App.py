import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report

# =============================
# ConfiguraciÃ³n general
# =============================
st.set_page_config(page_title="Ãrbol de DecisiÃ³n - ML App", layout="wide")

# =============================
# Generar dataset simulado
# =============================
@st.cache_data
def generar_datos(n_samples=400, n_features=6, random_state=42):
    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=4,
        n_redundant=0,
        n_classes=3,
        random_state=random_state
    )
    columnas = [f"feature_{i}" for i in range(X.shape[1])]
    df = pd.DataFrame(X, columns=columnas)
    df["target"] = y
    return df

# =============================
# Sidebar: parÃ¡metros
# =============================
st.sidebar.header("âš™ï¸ ParÃ¡metros del modelo")

# ParÃ¡metros del dataset
n_samples = st.sidebar.slider("NÃºmero de muestras", 200, 1000, 400, step=50)
n_features = st.sidebar.slider("NÃºmero de caracterÃ­sticas", 6, 12, 6)
test_size = st.sidebar.slider("ProporciÃ³n de prueba", 0.1, 0.5, 0.3, step=0.05)

# ParÃ¡metros del Ã¡rbol de decisiÃ³n
criterion = st.sidebar.selectbox("Criterio de divisiÃ³n", ["gini", "entropy", "log_loss"])
max_depth = st.sidebar.slider("Profundidad mÃ¡xima", 1, 15, 3)
min_samples_split = st.sidebar.slider("MÃ­nimo de muestras para dividir", 2, 20, 2)
min_samples_leaf = st.sidebar.slider("MÃ­nimo de muestras en hoja", 1, 20, 1)

# =============================
# Cargar dataset o generar
# =============================
st.title("ğŸŒ³ ClasificaciÃ³n con Ãrbol de DecisiÃ³n")

uploaded_file = st.file_uploader("Sube un archivo CSV (debe contener la columna 'target')", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("âœ… Dataset cargado exitosamente")
else:
    df = generar_datos(n_samples=n_samples, n_features=n_features)
    st.info("â„¹ï¸ Usando dataset simulado")

st.subheader("ğŸ“Š Vista previa del dataset")
st.write(df.head())

# =============================
# DivisiÃ³n de datos
# =============================
if "target" not in df.columns:
    st.error("âŒ El dataset debe contener una columna llamada 'target'")
else:
    X = df.drop("target", axis=1)
    y = df["target"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )

    st.write(f"ğŸ‘‰ TamaÃ±o entrenamiento: {X_train.shape[0]} | TamaÃ±o prueba: {X_test.shape[0]}")

    # =============================
    # Entrenar modelo
    # =============================
    clf = DecisionTreeClassifier(
        criterion=criterion,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        random_state=42
    )

    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    # =============================
    # Resultados
    # =============================
    acc = accuracy_score(y_test, y_pred)
    st.subheader("ğŸ“ˆ Resultados del Modelo")
    st.write(f"**Exactitud (Accuracy):** {acc:.3f}")

    st.text("ğŸ“Œ Reporte de ClasificaciÃ³n:")
    st.text(classification_report(y_test, y_pred))

    # =============================
    # Matriz de confusiÃ³n
    # =============================
    st.subheader("ğŸ“Œ Matriz de ConfusiÃ³n")
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots()
    ConfusionMatrixDisplay(cm).plot(ax=ax, cmap="Blues", colorbar=False)
    st.pyplot(fig)

    # =============================
    # VisualizaciÃ³n de dispersiÃ³n
    # =============================
    st.subheader("ğŸŒ VisualizaciÃ³n de Clases (2 primeras caracterÃ­sticas)")
    fig, ax = plt.subplots()
    scatter = ax.scatter(
        X_test.iloc[:, 0], X_test.iloc[:, 1],
        c=y_pred, cmap="viridis", alpha=0.7, edgecolors="k"
    )
    legend1 = ax.legend(*scatter.legend_elements(), title="Clases")
    ax.add_artist(legend1)
    plt.xlabel("Feature 0")
    plt.ylabel("Feature 1")
    st.pyplot(fig)

    # =============================
    # VisualizaciÃ³n del Ãrbol
    # =============================
    st.subheader("ğŸŒ³ VisualizaciÃ³n del Ãrbol de DecisiÃ³n")
    fig, ax = plt.subplots(figsize=(14, 6))
    plot_tree(
        clf,
        filled=True,
        feature_names=X.columns,
        class_names=[str(c) for c in np.unique(y)],
        rounded=True
    )
    st.pyplot(fig)
